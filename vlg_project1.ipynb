{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important Libraries...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>0</td>\n",
       "      <td>1.157565</td>\n",
       "      <td>-0.142219</td>\n",
       "      <td>1.043992</td>\n",
       "      <td>1.144946</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>-1.505100</td>\n",
       "      <td>-0.874137</td>\n",
       "      <td>-1.782724</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.255793</td>\n",
       "      <td>-0.154838</td>\n",
       "      <td>0.413029</td>\n",
       "      <td>-0.482939</td>\n",
       "      <td>-1.277953</td>\n",
       "      <td>-0.445082</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.924614</td>\n",
       "      <td>-0.432462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>0</td>\n",
       "      <td>1.424709</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>1.356778</td>\n",
       "      <td>1.368099</td>\n",
       "      <td>-0.318862</td>\n",
       "      <td>1.039765</td>\n",
       "      <td>-0.986854</td>\n",
       "      <td>-0.330184</td>\n",
       "      <td>-1.383120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424709</td>\n",
       "      <td>-1.066107</td>\n",
       "      <td>0.881258</td>\n",
       "      <td>-0.488691</td>\n",
       "      <td>-1.281223</td>\n",
       "      <td>-1.213291</td>\n",
       "      <td>0.122692</td>\n",
       "      <td>1.175627</td>\n",
       "      <td>-1.145360</td>\n",
       "      <td>0.451026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.375687</td>\n",
       "      <td>1.524455</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>-0.906909</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>1.606182</td>\n",
       "      <td>0.298557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028349</td>\n",
       "      <td>-0.968204</td>\n",
       "      <td>-1.233815</td>\n",
       "      <td>1.626613</td>\n",
       "      <td>-0.191802</td>\n",
       "      <td>1.115823</td>\n",
       "      <td>0.380284</td>\n",
       "      <td>-0.293960</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>1.381434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.478238</td>\n",
       "      <td>1.666142</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-0.362771</td>\n",
       "      <td>1.798104</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-1.121552</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>-0.593705</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>1.765114</td>\n",
       "      <td>0.313533</td>\n",
       "      <td>-0.329781</td>\n",
       "      <td>-1.220524</td>\n",
       "      <td>0.033114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.750874</td>\n",
       "      <td>0.267008</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.179867</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.279173</td>\n",
       "      <td>1.731765</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.850180</td>\n",
       "      <td>0.937321</td>\n",
       "      <td>-1.594972</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>1.582807</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>-0.254346</td>\n",
       "      <td>0.664230</td>\n",
       "      <td>1.831071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0          0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562  \\\n",
       "1          1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2          1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3          0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4          0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "5245       0  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978   \n",
       "5246       0  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765   \n",
       "5247       1 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909   \n",
       "5248       1 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104   \n",
       "5249       1 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999   \n",
       "\n",
       "           f_6       f_7       f_8  ...    f_1190    f_1191    f_1192   \n",
       "0    -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  \\\n",
       "1    -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941   \n",
       "2    -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953   \n",
       "3     0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384   \n",
       "4     0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5245 -1.505100 -0.874137 -1.782724  ...  1.195423 -0.255793 -0.154838   \n",
       "5246 -0.986854 -0.330184 -1.383120  ...  1.424709 -1.066107  0.881258   \n",
       "5247 -1.254247  1.606182  0.298557  ... -0.028349 -0.968204 -1.233815   \n",
       "5248 -0.214314  0.775400 -0.379267  ... -0.428752 -1.121552 -0.379267   \n",
       "5249 -0.279173  1.731765  0.564925  ... -0.303999 -0.850180  0.937321   \n",
       "\n",
       "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
       "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
       "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
       "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
       "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
       "\n",
       "[5250 rows x 1201 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features and labels......\n",
    "X = df.drop(\"labels\", axis=1).values\n",
    "y = df[\"labels\"].values\n",
    "y = np.where(y == 1, 1, 0) \n",
    "\n",
    "# Apply SMOTE to address data imbalance.....\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into train and test sets......\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now utilizing this flattend data directly for MLP classification "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonys\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-35 {color: black;background-color: white;}#sk-container-id-35 pre{padding: 0;}#sk-container-id-35 div.sk-toggleable {background-color: white;}#sk-container-id-35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-35 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-35 div.sk-item {position: relative;z-index: 1;}#sk-container-id-35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-35 div.sk-item::before, #sk-container-id-35 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-35 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-35 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-35 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-35 div.sk-label-container {text-align: center;}#sk-container-id-35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(base_estimator=MLPClassifier(random_state=42),\n",
       "                  random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(base_estimator=MLPClassifier(random_state=42),\n",
       "                  random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(base_estimator=MLPClassifier(random_state=42),\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base neural network\n",
    "base_estimator = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42)\n",
    "# Define the number of base estimators (number of MLP models to train)\n",
    "n_estimators = 10\n",
    "\n",
    "# Create an instance of the BaggingClassifier with the base estimator\n",
    "classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Accuracy and F1_score on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8987012987012987\n"
     ]
    }
   ],
   "source": [
    "# Predicting the labels for the test data using the classifier\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculating the confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculating the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Printing the accuracy score\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9003407155025555\n"
     ]
    }
   ],
   "source": [
    "# Print the F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.388242</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>-0.427619</td>\n",
       "      <td>-0.678964</td>\n",
       "      <td>-1.625735</td>\n",
       "      <td>0.262761</td>\n",
       "      <td>1.243040</td>\n",
       "      <td>1.537751</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-0.662884</td>\n",
       "      <td>-0.257091</td>\n",
       "      <td>-1.168413</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>-0.482520</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.539349</td>\n",
       "      <td>-1.682404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.451422</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-1.124326</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>-0.216224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>-1.760084</td>\n",
       "      <td>1.125450</td>\n",
       "      <td>-0.328047</td>\n",
       "      <td>-0.880305</td>\n",
       "      <td>-1.257607</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>2.021104</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>-0.423029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.128369</td>\n",
       "      <td>-0.537951</td>\n",
       "      <td>2.544358</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.904994</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>-0.495768</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-1.418468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.373589</td>\n",
       "      <td>-0.483701</td>\n",
       "      <td>-0.964782</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>-0.444567</td>\n",
       "      <td>-0.531935</td>\n",
       "      <td>-0.878660</td>\n",
       "      <td>1.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>1.746814</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>1.844524</td>\n",
       "      <td>-0.327977</td>\n",
       "      <td>1.226839</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>-1.003667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442288</td>\n",
       "      <td>-2.794472</td>\n",
       "      <td>-0.763468</td>\n",
       "      <td>-0.789832</td>\n",
       "      <td>-0.113209</td>\n",
       "      <td>-2.703150</td>\n",
       "      <td>-2.058728</td>\n",
       "      <td>1.070627</td>\n",
       "      <td>-0.458045</td>\n",
       "      <td>-0.435825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.423209</td>\n",
       "      <td>-0.983594</td>\n",
       "      <td>-1.694170</td>\n",
       "      <td>1.197507</td>\n",
       "      <td>1.044211</td>\n",
       "      <td>0.518777</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-0.365174</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.624450</td>\n",
       "      <td>-3.200223</td>\n",
       "      <td>0.711422</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>-1.656639</td>\n",
       "      <td>0.707360</td>\n",
       "      <td>-0.562290</td>\n",
       "      <td>1.471181</td>\n",
       "      <td>-0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2246</td>\n",
       "      <td>0.889888</td>\n",
       "      <td>-0.319077</td>\n",
       "      <td>0.849589</td>\n",
       "      <td>0.822723</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>-0.910127</td>\n",
       "      <td>0.889888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889888</td>\n",
       "      <td>-2.226556</td>\n",
       "      <td>-0.090717</td>\n",
       "      <td>-1.393713</td>\n",
       "      <td>-0.896694</td>\n",
       "      <td>-0.399675</td>\n",
       "      <td>-0.856395</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>0.863022</td>\n",
       "      <td>-0.601169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2247</td>\n",
       "      <td>1.005737</td>\n",
       "      <td>-0.064755</td>\n",
       "      <td>1.163494</td>\n",
       "      <td>1.163494</td>\n",
       "      <td>1.163494</td>\n",
       "      <td>0.724028</td>\n",
       "      <td>0.712760</td>\n",
       "      <td>-0.785929</td>\n",
       "      <td>-1.225394</td>\n",
       "      <td>...</td>\n",
       "      <td>1.163494</td>\n",
       "      <td>-1.270468</td>\n",
       "      <td>-0.932417</td>\n",
       "      <td>-1.169053</td>\n",
       "      <td>-0.008414</td>\n",
       "      <td>-0.605636</td>\n",
       "      <td>-0.323927</td>\n",
       "      <td>1.163494</td>\n",
       "      <td>-1.315541</td>\n",
       "      <td>0.047928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2248</td>\n",
       "      <td>1.252086</td>\n",
       "      <td>1.223561</td>\n",
       "      <td>0.153859</td>\n",
       "      <td>-0.987156</td>\n",
       "      <td>0.239435</td>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-1.158309</td>\n",
       "      <td>1.237823</td>\n",
       "      <td>-1.272410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581740</td>\n",
       "      <td>-1.386512</td>\n",
       "      <td>0.809943</td>\n",
       "      <td>-1.243885</td>\n",
       "      <td>0.153859</td>\n",
       "      <td>-0.630589</td>\n",
       "      <td>1.594391</td>\n",
       "      <td>1.252086</td>\n",
       "      <td>-1.429300</td>\n",
       "      <td>1.408976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>2249</td>\n",
       "      <td>1.042624</td>\n",
       "      <td>-0.129166</td>\n",
       "      <td>1.066538</td>\n",
       "      <td>1.030667</td>\n",
       "      <td>1.162195</td>\n",
       "      <td>0.707827</td>\n",
       "      <td>-1.396612</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>-1.025944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078495</td>\n",
       "      <td>-1.193343</td>\n",
       "      <td>0.086061</td>\n",
       "      <td>-0.081338</td>\n",
       "      <td>-0.978116</td>\n",
       "      <td>-0.368307</td>\n",
       "      <td>-0.129166</td>\n",
       "      <td>1.090452</td>\n",
       "      <td>-1.444440</td>\n",
       "      <td>0.468686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>2250</td>\n",
       "      <td>-1.319572</td>\n",
       "      <td>-0.485173</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>2.323293</td>\n",
       "      <td>-0.139202</td>\n",
       "      <td>-0.953250</td>\n",
       "      <td>0.084661</td>\n",
       "      <td>-0.566577</td>\n",
       "      <td>1.427840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505524</td>\n",
       "      <td>-0.220607</td>\n",
       "      <td>-0.871845</td>\n",
       "      <td>0.654495</td>\n",
       "      <td>0.430631</td>\n",
       "      <td>-0.444470</td>\n",
       "      <td>-0.118851</td>\n",
       "      <td>0.471334</td>\n",
       "      <td>-0.078149</td>\n",
       "      <td>-0.566577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0        1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  \\\n",
       "1        2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658   \n",
       "2        3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961   \n",
       "3        4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839   \n",
       "4        5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2245  2246  0.889888 -0.319077  0.849589  0.822723  0.876455  0.325704   \n",
       "2246  2247  1.005737 -0.064755  1.163494  1.163494  1.163494  0.724028   \n",
       "2247  2248  1.252086  1.223561  0.153859 -0.987156  0.239435 -0.003031   \n",
       "2248  2249  1.042624 -0.129166  1.066538  1.030667  1.162195  0.707827   \n",
       "2249  2250 -1.319572 -0.485173 -0.098500  2.323293 -0.139202 -0.953250   \n",
       "\n",
       "           f_6       f_7       f_8  ...    f_1190    f_1191    f_1192   \n",
       "0     1.243040  1.537751 -0.352028  ... -0.776403 -0.662884 -0.257091  \\\n",
       "1    -1.124326  0.729430 -0.216224  ...  0.379635 -1.760084  1.125450   \n",
       "2    -0.495768  0.060111 -1.418468  ...  1.165254 -1.373589 -0.483701   \n",
       "3    -0.085519  0.379008 -1.003667  ... -0.442288 -2.794472 -0.763468   \n",
       "4    -0.298612 -0.365174  0.738447  ... -2.624450 -3.200223  0.711422   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2245  0.876455 -0.910127  0.889888  ...  0.889888 -2.226556 -0.090717   \n",
       "2246  0.712760 -0.785929 -1.225394  ...  1.163494 -1.270468 -0.932417   \n",
       "2247 -1.158309  1.237823 -1.272410  ...  0.581740 -1.386512  0.809943   \n",
       "2248 -1.396612  0.014319 -1.025944  ...  1.078495 -1.193343  0.086061   \n",
       "2249  0.084661 -0.566577  1.427840  ... -0.505524 -0.220607 -0.871845   \n",
       "\n",
       "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0    -1.168413  0.223260 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
       "1    -0.328047 -0.880305 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
       "2    -0.964782 -0.869555  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
       "3    -0.789832 -0.113209 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
       "4    -0.190394  0.337224 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2245 -1.393713 -0.896694 -0.399675 -0.856395  0.876455  0.863022 -0.601169  \n",
       "2246 -1.169053 -0.008414 -0.605636 -0.323927  1.163494 -1.315541  0.047928  \n",
       "2247 -1.243885  0.153859 -0.630589  1.594391  1.252086 -1.429300  1.408976  \n",
       "2248 -0.081338 -0.978116 -0.368307 -0.129166  1.090452 -1.444440  0.468686  \n",
       "2249  0.654495  0.430631 -0.444470 -0.118851  0.471334 -0.078149 -0.566577  \n",
       "\n",
       "[2250 rows x 1201 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat=test_data.drop(\"id\", axis=1).values\n",
    "test_feat\n",
    "pred=[]\n",
    "pred = classifier.predict(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the index numbers and predictions\n",
    "results = pd.DataFrame({'Index': test_data.index, 'Prediction': pred})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('results.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>2248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>2249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Prediction\n",
       "0         0           0\n",
       "1         1           0\n",
       "2         2           0\n",
       "3         3           0\n",
       "4         4           0\n",
       "...     ...         ...\n",
       "2245   2245           0\n",
       "2246   2246           0\n",
       "2247   2247           1\n",
       "2248   2248           0\n",
       "2249   2249           1\n",
       "\n",
       "[2250 rows x 2 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=pd.read_csv('results.csv')\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
